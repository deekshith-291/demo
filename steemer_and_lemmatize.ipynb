{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0z7SAqOnUpZ8QmYvCPCKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deekshith-291/demo/blob/master/steemer_and_lemmatize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7otdpfU_lYuQ"
      },
      "outputs": [],
      "source": [
        "article_text=\"Just what is agility in the context of software engineering work? Ivar Jacobs\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "7H7_nnHjlsWy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = article_text.lower()\n",
        "article_text"
      ],
      "metadata": {
        "id": "x0MGS5Yrlxt0",
        "outputId": "53bca3bd-69a4-4bd8-db91-683fa4070336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'just what is agility in the context of software engineering work? ivar jacobs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text = re.sub(r'[^a-zA-Z\\s]', '', article_text)\n",
        "clean_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SlLUKFCPpFed",
        "outputId": "296102d2-7e6a-43a6-eb81-16272d2934c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'just what is agility in the context of software engineering work ivar jacobs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download both punkt and punkt_tab to be safe\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "article_text = \"Natural Language Processing is a fascinating field. It helps computers understand human language.\"\n",
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "print(sentence_list)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SBgv-NcpSJN",
        "outputId": "d2c408a3-6f1c-494c-f856-f834e8ff548f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural Language Processing is a fascinating field.', 'It helps computers understand human language.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(clean_text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaMyQF4wpSFm",
        "outputId": "d22c7660-f63f-43cc-e4a1-728f2e6fdc82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['just',\n",
              " 'what',\n",
              " 'is',\n",
              " 'agility',\n",
              " 'in',\n",
              " 'the',\n",
              " 'context',\n",
              " 'of',\n",
              " 'software',\n",
              " 'engineering',\n",
              " 'work',\n",
              " 'ivar',\n",
              " 'jacobs']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')  # Download stopwords dataset\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1w8HBQ3p668",
        "outputId": "8bfb7f75-4068-471c-a9b7-96b23c64aa44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies = {}\n",
        "for word in tokens:\n",
        "    if word not in stop_words:\n",
        "        if word not in word_frequencies:\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1\n",
        "word_frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtV9yIEoqAJ0",
        "outputId": "8302ac08-c6e4-4819-ce8c-a0921deea390"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agility': 1,\n",
              " 'context': 1,\n",
              " 'software': 1,\n",
              " 'engineering': 1,\n",
              " 'work': 1,\n",
              " 'ivar': 1,\n",
              " 'jacobs': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "dictionary = Counter(word_frequencies)\n",
        "dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpYqvtzCqFux",
        "outputId": "bc1a8c31-04d9-4aaa-e65b-6cae01cdceac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'agility': 1,\n",
              "         'context': 1,\n",
              "         'software': 1,\n",
              "         'engineering': 1,\n",
              "         'work': 1,\n",
              "         'ivar': 1,\n",
              "         'jacobs': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer"
      ],
      "metadata": {
        "id": "Y-jjsBh1qLL2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "\n",
        "print(porter.stem(\"cats\"))\n",
        "print(lancaster.stem(\"cats\"))\n",
        "print(porter.stem(\"troubling\"))\n",
        "print(lancaster.stem(\"troubling\"))\n",
        "print(porter.stem(\"troubled\"))\n",
        "print(lancaster.stem(\"troubled\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYstZdkUqPfk",
        "outputId": "ab70ff58-31b0-429a-bdcd-3d8a336250a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "cat\n",
            "troubl\n",
            "troubl\n",
            "troubl\n",
            "troubl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\", \"stabil\", \"destabilize\"]\n",
        "print(\"{:20}{:20}{:20}\".format(\"Word\", \"Porter Stemmer\", \"Lancaster Stemmer\"))\n",
        "for word in word_list:\n",
        "    print(\"{:20}{:20}{:20}\".format(word, porter.stem(word), lancaster.stem(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdbgiw_7qVyx",
        "outputId": "73fa2562-eb70-43c0-e246-9a210b18dcd1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Lancaster Stemmer   \n",
            "friend              friend              friend              \n",
            "friendship          friendship          friend              \n",
            "friends             friend              friend              \n",
            "friendships         friendship          friend              \n",
            "stabil              stabil              stabl               \n",
            "destabilize         destabil            dest                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_sentence = []\n",
        "for word in tokens:\n",
        "    stem_sentence.append(porter.stem(word))\n",
        "    stem_sentence.append(\" \")\n",
        "stem_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM1KBjbaqbEa",
        "outputId": "9c16f192-1e62-452e-cf4e-f733d3596f01"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['just',\n",
              " ' ',\n",
              " 'what',\n",
              " ' ',\n",
              " 'is',\n",
              " ' ',\n",
              " 'agil',\n",
              " ' ',\n",
              " 'in',\n",
              " ' ',\n",
              " 'the',\n",
              " ' ',\n",
              " 'context',\n",
              " ' ',\n",
              " 'of',\n",
              " ' ',\n",
              " 'softwar',\n",
              " ' ',\n",
              " 'engin',\n",
              " ' ',\n",
              " 'work',\n",
              " ' ',\n",
              " 'ivar',\n",
              " ' ',\n",
              " 'jacob',\n",
              " ' ']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "ZhE05ZWJqiYT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo3UhVI-qo9J",
        "outputId": "537bb0c7-f849-461d-eed8-e71c56ab97d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_word(word):\n",
        "    return lemmatizer.lemmatize(word)"
      ],
      "metadata": {
        "id": "TfMm4Gz9qs6X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = [\"word1\", \"word2\", \"word3\"]\n",
        "print(\"{:20}{:20}\".format(\"Word\", \"Lemma\"))\n",
        "for word in word_list:\n",
        "    print(\"{:20}{:20}\".format(word, lemmatize_word(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCq5Hzb7qxxT",
        "outputId": "e7f0f175-a2cc-4abe-9124-44a86abd9ef9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Lemma               \n",
            "word1               word1               \n",
            "word2               word2               \n",
            "word3               word3               \n"
          ]
        }
      ]
    }
  ]
}